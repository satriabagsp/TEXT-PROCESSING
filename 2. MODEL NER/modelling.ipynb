{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at iteration 0: {'ner': np.float32(14065.617)}\n",
      "Losses at iteration 1: {'ner': np.float32(10343.373)}\n",
      "Losses at iteration 2: {'ner': np.float32(8645.48)}\n",
      "Losses at iteration 3: {'ner': np.float32(7764.442)}\n",
      "Losses at iteration 4: {'ner': np.float32(7050.838)}\n",
      "Losses at iteration 5: {'ner': np.float32(6634.4854)}\n",
      "Losses at iteration 6: {'ner': np.float32(6186.873)}\n",
      "Losses at iteration 7: {'ner': np.float32(5917.1665)}\n",
      "Losses at iteration 8: {'ner': np.float32(5724.998)}\n",
      "Losses at iteration 9: {'ner': np.float32(5478.1646)}\n",
      "Losses at iteration 10: {'ner': np.float32(5293.305)}\n",
      "Losses at iteration 11: {'ner': np.float32(5147.912)}\n",
      "Losses at iteration 12: {'ner': np.float32(4913.897)}\n",
      "Losses at iteration 13: {'ner': np.float32(4717.1787)}\n",
      "Losses at iteration 14: {'ner': np.float32(4637.5503)}\n",
      "Losses at iteration 15: {'ner': np.float32(4415.6865)}\n",
      "Losses at iteration 16: {'ner': np.float32(4521.2607)}\n",
      "Losses at iteration 17: {'ner': np.float32(4378.7397)}\n",
      "Losses at iteration 18: {'ner': np.float32(4331.8657)}\n",
      "Losses at iteration 19: {'ner': np.float32(4124.1377)}\n",
      "Losses at iteration 20: {'ner': np.float32(4108.371)}\n",
      "Losses at iteration 21: {'ner': np.float32(4017.2646)}\n",
      "Losses at iteration 22: {'ner': np.float32(3981.038)}\n",
      "Losses at iteration 23: {'ner': np.float32(3898.1616)}\n",
      "Losses at iteration 24: {'ner': np.float32(3872.1162)}\n",
      "Losses at iteration 25: {'ner': np.float32(3911.9753)}\n",
      "Losses at iteration 26: {'ner': np.float32(3755.9114)}\n",
      "Losses at iteration 27: {'ner': np.float32(3625.3752)}\n",
      "Losses at iteration 28: {'ner': np.float32(3710.738)}\n",
      "Losses at iteration 29: {'ner': np.float32(3554.626)}\n",
      "Losses at iteration 30: {'ner': np.float32(3558.0762)}\n",
      "Losses at iteration 31: {'ner': np.float32(3510.8877)}\n",
      "Losses at iteration 32: {'ner': np.float32(3456.7466)}\n",
      "Losses at iteration 33: {'ner': np.float32(3392.278)}\n",
      "Losses at iteration 34: {'ner': np.float32(3360.068)}\n",
      "Losses at iteration 35: {'ner': np.float32(3279.814)}\n",
      "Losses at iteration 36: {'ner': np.float32(3373.6296)}\n",
      "Losses at iteration 37: {'ner': np.float32(3222.5217)}\n",
      "Losses at iteration 38: {'ner': np.float32(3223.2756)}\n",
      "Losses at iteration 39: {'ner': np.float32(3217.118)}\n",
      "Losses at iteration 40: {'ner': np.float32(3084.1223)}\n",
      "Losses at iteration 41: {'ner': np.float32(3168.3816)}\n",
      "Losses at iteration 42: {'ner': np.float32(3095.9763)}\n",
      "Losses at iteration 43: {'ner': np.float32(3018.732)}\n",
      "Losses at iteration 44: {'ner': np.float32(3015.759)}\n",
      "Losses at iteration 45: {'ner': np.float32(3056.8118)}\n",
      "Losses at iteration 46: {'ner': np.float32(2996.8035)}\n",
      "Losses at iteration 47: {'ner': np.float32(2953.877)}\n",
      "Losses at iteration 48: {'ner': np.float32(2913.2275)}\n",
      "Losses at iteration 49: {'ner': np.float32(2950.6265)}\n",
      "Losses at iteration 50: {'ner': np.float32(2908.752)}\n",
      "Losses at iteration 51: {'ner': np.float32(2811.1523)}\n",
      "Losses at iteration 52: {'ner': np.float32(2879.7979)}\n",
      "Losses at iteration 53: {'ner': np.float32(2849.659)}\n",
      "Losses at iteration 54: {'ner': np.float32(2824.0852)}\n",
      "Losses at iteration 55: {'ner': np.float32(2769.2173)}\n",
      "Losses at iteration 56: {'ner': np.float32(2729.6677)}\n",
      "Losses at iteration 57: {'ner': np.float32(2788.7295)}\n",
      "Losses at iteration 58: {'ner': np.float32(2699.1868)}\n",
      "Losses at iteration 59: {'ner': np.float32(2728.8577)}\n",
      "Losses at iteration 60: {'ner': np.float32(2742.735)}\n",
      "Losses at iteration 61: {'ner': np.float32(2754.993)}\n",
      "Losses at iteration 62: {'ner': np.float32(2630.4863)}\n",
      "Losses at iteration 63: {'ner': np.float32(2688.4568)}\n",
      "Losses at iteration 64: {'ner': np.float32(2724.1724)}\n",
      "Losses at iteration 65: {'ner': np.float32(2635.428)}\n",
      "Losses at iteration 66: {'ner': np.float32(2688.204)}\n",
      "Losses at iteration 67: {'ner': np.float32(2507.5999)}\n",
      "Losses at iteration 68: {'ner': np.float32(2613.347)}\n",
      "Losses at iteration 69: {'ner': np.float32(2569.8496)}\n",
      "Losses at iteration 70: {'ner': np.float32(2653.0645)}\n",
      "Losses at iteration 71: {'ner': np.float32(2563.1643)}\n",
      "Losses at iteration 72: {'ner': np.float32(2437.1628)}\n",
      "Losses at iteration 73: {'ner': np.float32(2514.0032)}\n",
      "Losses at iteration 74: {'ner': np.float32(2508.8486)}\n",
      "Losses at iteration 75: {'ner': np.float32(2432.4595)}\n",
      "Losses at iteration 76: {'ner': np.float32(2455.7922)}\n",
      "Losses at iteration 77: {'ner': np.float32(2448.9902)}\n",
      "Losses at iteration 78: {'ner': np.float32(2414.8325)}\n",
      "Losses at iteration 79: {'ner': np.float32(2444.155)}\n",
      "Losses at iteration 80: {'ner': np.float32(2481.4517)}\n",
      "Losses at iteration 81: {'ner': np.float32(2422.6328)}\n",
      "Losses at iteration 82: {'ner': np.float32(2488.7815)}\n",
      "Losses at iteration 83: {'ner': np.float32(2369.61)}\n",
      "Losses at iteration 84: {'ner': np.float32(2359.4268)}\n",
      "Losses at iteration 85: {'ner': np.float32(2367.0327)}\n",
      "Losses at iteration 86: {'ner': np.float32(2416.1064)}\n",
      "Losses at iteration 87: {'ner': np.float32(2351.6948)}\n",
      "Losses at iteration 88: {'ner': np.float32(2432.4243)}\n",
      "Losses at iteration 89: {'ner': np.float32(2422.7876)}\n",
      "Losses at iteration 90: {'ner': np.float32(2358.813)}\n",
      "Losses at iteration 91: {'ner': np.float32(2291.113)}\n",
      "Losses at iteration 92: {'ner': np.float32(2315.47)}\n",
      "Losses at iteration 93: {'ner': np.float32(2389.79)}\n",
      "Losses at iteration 94: {'ner': np.float32(2341.184)}\n",
      "Losses at iteration 95: {'ner': np.float32(2411.6824)}\n",
      "Losses at iteration 96: {'ner': np.float32(2354.726)}\n",
      "Losses at iteration 97: {'ner': np.float32(2307.0986)}\n",
      "Losses at iteration 98: {'ner': np.float32(2252.0103)}\n",
      "Losses at iteration 99: {'ner': np.float32(2270.2463)}\n",
      "Losses at iteration 100: {'ner': np.float32(2322.6003)}\n",
      "Losses at iteration 101: {'ner': np.float32(2325.5955)}\n",
      "Losses at iteration 102: {'ner': np.float32(2314.2961)}\n",
      "Losses at iteration 103: {'ner': np.float32(2287.0728)}\n",
      "Losses at iteration 104: {'ner': np.float32(2129.634)}\n",
      "Losses at iteration 105: {'ner': np.float32(2232.2278)}\n",
      "Losses at iteration 106: {'ner': np.float32(2219.0862)}\n",
      "Losses at iteration 107: {'ner': np.float32(2289.643)}\n",
      "Losses at iteration 108: {'ner': np.float32(2214.131)}\n",
      "Losses at iteration 109: {'ner': np.float32(2200.8591)}\n",
      "Losses at iteration 110: {'ner': np.float32(2189.7864)}\n",
      "Losses at iteration 111: {'ner': np.float32(2205.352)}\n",
      "Losses at iteration 112: {'ner': np.float32(2226.9348)}\n",
      "Losses at iteration 113: {'ner': np.float32(2265.8599)}\n",
      "Losses at iteration 114: {'ner': np.float32(2154.096)}\n",
      "Losses at iteration 115: {'ner': np.float32(2225.3328)}\n",
      "Losses at iteration 116: {'ner': np.float32(2137.3323)}\n",
      "Losses at iteration 117: {'ner': np.float32(2178.6692)}\n",
      "Losses at iteration 118: {'ner': np.float32(2269.6907)}\n",
      "Losses at iteration 119: {'ner': np.float32(2124.6565)}\n",
      "Losses at iteration 120: {'ner': np.float32(2166.1228)}\n",
      "Losses at iteration 121: {'ner': np.float32(2169.929)}\n",
      "Losses at iteration 122: {'ner': np.float32(2214.4553)}\n",
      "Losses at iteration 123: {'ner': np.float32(2066.986)}\n",
      "Losses at iteration 124: {'ner': np.float32(2111.4604)}\n",
      "Losses at iteration 125: {'ner': np.float32(2129.1462)}\n",
      "Losses at iteration 126: {'ner': np.float32(2187.2795)}\n",
      "Losses at iteration 127: {'ner': np.float32(2064.111)}\n",
      "Losses at iteration 128: {'ner': np.float32(2110.214)}\n",
      "Losses at iteration 129: {'ner': np.float32(2049.4614)}\n",
      "Losses at iteration 130: {'ner': np.float32(2048.1929)}\n",
      "Losses at iteration 131: {'ner': np.float32(2165.341)}\n",
      "Losses at iteration 132: {'ner': np.float32(2120.0232)}\n",
      "Losses at iteration 133: {'ner': np.float32(2106.8809)}\n",
      "Losses at iteration 134: {'ner': np.float32(2123.9353)}\n",
      "Losses at iteration 135: {'ner': np.float32(2065.0237)}\n",
      "Losses at iteration 136: {'ner': np.float32(2133.2798)}\n",
      "Losses at iteration 137: {'ner': np.float32(2099.4338)}\n",
      "Losses at iteration 138: {'ner': np.float32(2099.707)}\n",
      "Losses at iteration 139: {'ner': np.float32(2134.5698)}\n",
      "Losses at iteration 140: {'ner': np.float32(2149.6326)}\n",
      "Losses at iteration 141: {'ner': np.float32(2046.4873)}\n",
      "Losses at iteration 142: {'ner': np.float32(2025.1604)}\n",
      "Losses at iteration 143: {'ner': np.float32(2073.1506)}\n",
      "Losses at iteration 144: {'ner': np.float32(2047.9724)}\n",
      "Losses at iteration 145: {'ner': np.float32(2132.5642)}\n",
      "Losses at iteration 146: {'ner': np.float32(2038.5413)}\n",
      "Losses at iteration 147: {'ner': np.float32(2072.2874)}\n",
      "Losses at iteration 148: {'ner': np.float32(2024.49)}\n",
      "Losses at iteration 149: {'ner': np.float32(2091.9077)}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import json\n",
    "with open('data_full.json', 'r', encoding='utf-8') as f:\n",
    "    TRAIN_DATA = json.load(f)\n",
    "nlp = spacy.blank(\"id\")\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "for item in TRAIN_DATA:\n",
    "    for start, end, label in item['entities']:\n",
    "        ner.add_label(label)\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(150): \n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            examples = []\n",
    "            for d in batch:\n",
    "                doc = nlp.make_doc(d['text'])\n",
    "                example = Example.from_dict(doc, {\"entities\": d['entities']})\n",
    "                examples.append(example)\n",
    "            nlp.update(examples, drop=0.5, losses=losses)\n",
    "        print(f\"Losses at iteration {itn}: {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 'model'\n"
     ]
    }
   ],
   "source": [
    "nlp.to_disk(\"model\")\n",
    "print(\"Model saved to 'model'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Data Nasional (PDN)', 'ORGANIZATION'), ('Badan Usaha Milik Negara', 'ORGANIZATION'), ('BUMN', 'ORGANIZATION'), ('Arya Sinulingga', 'PERSON'), ('BUMN', 'ORGANIZATION'), ('Erick Thohir', 'PERSON'), ('Jakarta', 'LOCATION'), ('PT Pertamina (Persero)', 'ORGANIZATION'), ('Telkom', 'ORGANIZATION'), ('BUMN', 'ORGANIZATION'), ('BUMN', 'ORGANIZATION')]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Keamanan dan perlindungan data menjadi isu hangat usai Pusat Data Nasional (PDN) diretas beberapa waktu lalu. Sehingga, semua pihak termasuk perusahaan Badan Usaha Milik Negara (BUMN) perlu mewaspadai serangan ransomware.\n",
    "Staf Khusus Menteri BUMN Arya Sinulingga mengatakan, Menteri BUMN Erick Thohir meminta semua perusahaan pelat merah memperkuat sistem keamanannya.\n",
    "\n",
    "\"Kita dengan kejadian PDN Ini memang Pak Menteri juga meminta kita semua memperkuat keamanan sistemnya semua,\" ujarnya di Jakarta, Kamis (4/7/2024).\n",
    "Perusahaan negara di semua sektor mulai dari sektor perbankan, PT Pertamina (Persero), Telkom, dan yang lainnya diminta untuk tidak meremehkan keamanan sistem data.\n",
    "\n",
    "\"Apa pun ceritanya keamanan siber ini penting dan ini kejadian walaupun kemarin kita tidak kena di BUMN tapi harus jadi peringatan bagi semua untuk memperkuat,\" sebutnya.\n",
    "\n",
    "Menurutnya, backup data perlu dilakukan untuk mengantisipasi hal yang tidak diinginkan di kemudian hari. \"Backup mandatori lah itu yang harus dilakukan BUMN supaya kalau ada apa apa bisa menggantikan dengan cepat,\" pungkasnya.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
